<!-- This is the markdown template for the final project of the Building AI course, 
created by Reaktor Innovations and University of Helsinki. 
Copy the template, paste it to your GitHub README and edit! -->

# Detecting inappropriate language with AI

Final project for the Building AI course

## Summary

This project aims to create an AI-powered bot that can effectively detect inappropriate language and respond with a warning. The technology can be used in various applications, including chatbots, social media platforms, and other digital interfaces where language can be monitored and censored.

## Background

The internet has provided a platform for freedom of expression, but it also comes with risks such as hate speech, offensive language, and other types of inappropriate content. With this project, we seek to develop a solution that can mitigate these risks by automatically detecting and filtering out language deemed inappropriate or offensive.

## How is it used?

The bot will be integrated into a bio-creator tool, where users can create and share personal descriptions. Using AI methods, the bot will scan and analyze the input data for any inappropriate or hateful language. This will not only eliminate inappropriate words but also identify and flag any harmful language that may be disguised or implicit.

![Image](/badwords.png)

## Data sources and AI methods

The AI bot will be trained using data sourced from users. The collected data will be used to develop a language model that can understand the context and intent of the input text. The model will be implemented using state-of-the-art natural language processing (NLP) techniques to effectively identify inappropriate language and hate speech.

## Challenges

The bot will have some limitations, particularly in detecting inappropriate language and hate speech in languages it is not trained on. Additionally, while the model can detect most forms of inappropriate language, there may be some that it cannot identify.

## What next?

This project has significant potential for use in various platforms, including social media, messaging, and chatbots. By limiting the spread of inappropriate language and hate speech, we can create safer online spaces and promote healthy communication. Future work could include improving the model's accuracy and incorporating it into other applications to maximize its impact.
