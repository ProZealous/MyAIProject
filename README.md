<!-- This is the markdown template for the final project of the Building AI course, 
created by Reaktor Innovations and University of Helsinki. 
Copy the template, paste it to your GitHub README and edit! -->

# Detecting inappropriate language with AI

Final project for the Building AI course

## Summary

The project is about a bot that can detect inappropriate language and responding with a warning. This can be used in chatbots to detect when a user is using an inappropriate language. Another example of when this can be used can be when inputing text into a specific scenario, such as a bio description of a profile.

## Background

This project can solve inappropriate use of language on many platforms, for example on Social Medias where a younger audiences can be found. An example could Instagram comments, we don't want to see inappropriate languages so a system like this can be useful to remove comments with hateful speech/bad words.

## How is it used?

For the sake of this project, it will be used in a bio-creator where users can tell people about themselves. The bot will detect inappropriate language and hateful speech. This doesn't necessarily need to have inappropriate words but could be hateful which it will detect.

![Image](/badwords.png)

## Data sources and AI methods

The data will be collected from the users, the input we receive from users will be used for the AI to detect if there is any sort of inappropriate language or hateful speech.

## Challenges

The bot won't be able to detect inappropriate language or hateful speech in every language, the bot will also not be able to detect every sort of bad language.

## What next?

This project could be very useful in the future for platforms and many places online to avoid and limit the amount of hateful language that is being used today. 
